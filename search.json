[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "cmdstanpy for Regression Monkeys",
    "section": "",
    "text": "Welcome\nこのQuarto Bookは以下のシリーズと連動して運用されています:",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "cmdstanpy for Regression Monkeys",
    "section": "References",
    "text": "References",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "posts/bayesianstatistics101/binomial_toymodel.html",
    "href": "posts/bayesianstatistics101/binomial_toymodel.html",
    "title": "1  二項分布を用いたベイジアンモデリング",
    "section": "",
    "text": "Code\nfrom cmdstanpy import CmdStanModel\n\ndata = {\n \"alpha\": 1,\n \"beta\": 1,\n \"N\" : 20,\n \"Y\" : [0,1,0,0,0,0,0,0,0,1,1,1,0,0,1,0,0,1,0,0]\n}\n\nmodel = CmdStanModel(stan_file=\"../../stancode/binomial_toymodel_01.stan\")\n\n\n12:01:02 - cmdstanpy - INFO - compiling stan file /home/runner/work/cmdstan_for_regression_monkey/cmdstan_for_regression_monkey/stancode/binomial_toymodel_01.stan to exe file /home/runner/work/cmdstan_for_regression_monkey/cmdstan_for_regression_monkey/stancode/binomial_toymodel_01\n12:01:08 - cmdstanpy - INFO - compiled model executable: /home/runner/work/cmdstan_for_regression_monkey/cmdstan_for_regression_monkey/stancode/binomial_toymodel_01\n\n\n\n\nCode\nfit = model.sample(data=data, show_console = True)\n\n\n12:01:08 - cmdstanpy - INFO - Chain [1] start processing\n12:01:08 - cmdstanpy - INFO - Chain [2] start processing\n12:01:08 - cmdstanpy - INFO - Chain [3] start processing\n12:01:08 - cmdstanpy - INFO - Chain [4] start processing\n12:01:08 - cmdstanpy - INFO - Chain [1] done processing\n12:01:08 - cmdstanpy - INFO - Chain [2] done processing\n12:01:08 - cmdstanpy - INFO - Chain [4] done processing\n12:01:08 - cmdstanpy - INFO - Chain [3] done processing\n\n\nChain [1] method = sample (Default)\nChain [1] sample\nChain [1] num_samples = 1000 (Default)\nChain [1] num_warmup = 1000 (Default)\nChain [1] save_warmup = false (Default)\nChain [1] thin = 1 (Default)\nChain [1] adapt\nChain [1] engaged = true (Default)\nChain [1] gamma = 0.05 (Default)\nChain [1] delta = 0.8 (Default)\nChain [1] kappa = 0.75 (Default)\nChain [1] t0 = 10 (Default)\nChain [1] init_buffer = 75 (Default)\nChain [1] term_buffer = 50 (Default)\nChain [1] window = 25 (Default)\nChain [1] save_metric = false (Default)\nChain [1] algorithm = hmc (Default)\nChain [1] hmc\nChain [1] engine = nuts (Default)\nChain [1] nuts\nChain [1] max_depth = 10 (Default)\nChain [1] metric = diag_e (Default)\nChain [1] metric_file =  (Default)\nChain [1] stepsize = 1 (Default)\nChain [1] stepsize_jitter = 0 (Default)\nChain [1] num_chains = 1 (Default)\nChain [2] method = sample (Default)\nChain [1] id = 1 (Default)\nChain [1] data\nChain [1] file = /tmp/tmpbd3i87cn/m4hm5zyi.json\nChain [1] init = 2 (Default)\nChain [1] random\nChain [1] seed = 26068\nChain [1] output\nChain [1] file = /tmp/tmpbd3i87cn/binomial_toymodel_013uxepct5/binomial_toymodel_01-20241101120108_1.csv\nChain [1] diagnostic_file =  (Default)\nChain [1] refresh = 100 (Default)\nChain [1] sig_figs = -1 (Default)\nChain [1] profile_file = profile.csv (Default)\nChain [1] save_cmdstan_config = false (Default)\nChain [1] num_threads = 1 (Default)\nChain [1] \nChain [2] sample\nChain [2] num_samples = 1000 (Default)\nChain [2] num_warmup = 1000 (Default)\nChain [2] save_warmup = false (Default)\nChain [2] thin = 1 (Default)\nChain [2] adapt\nChain [2] engaged = true (Default)\nChain [2] gamma = 0.05 (Default)\nChain [2] delta = 0.8 (Default)\nChain [2] kappa = 0.75 (Default)\nChain [2] t0 = 10 (Default)\nChain [2] init_buffer = 75 (Default)\nChain [2] term_buffer = 50 (Default)\nChain [2] window = 25 (Default)\nChain [2] save_metric = false (Default)\nChain [2] algorithm = hmc (Default)\nChain [2] hmc\nChain [2] engine = nuts (Default)\nChain [2] nuts\nChain [2] max_depth = 10 (Default)\nChain [2] metric = diag_e (Default)\nChain [2] metric_file =  (Default)\nChain [2] stepsize = 1 (Default)\nChain [2] stepsize_jitter = 0 (Default)\nChain [2] num_chains = 1 (Default)\nChain [2] id = 2\nChain [2] data\nChain [2] file = /tmp/tmpbd3i87cn/m4hm5zyi.json\nChain [2] init = 2 (Default)\nChain [2] random\nChain [2] seed = 26068\nChain [4] method = sample (Default)\nChain [1] \nChain [1] Gradient evaluation took 4e-06 seconds\nChain [1] 1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds.\nChain [1] Adjust your expectations accordingly!\nChain [1] \nChain [1] \nChain [4] sample\nChain [4] num_samples = 1000 (Default)\nChain [4] num_warmup = 1000 (Default)\nChain [4] save_warmup = false (Default)\nChain [4] thin = 1 (Default)\nChain [4] adapt\nChain [4] engaged = true (Default)\nChain [4] gamma = 0.05 (Default)\nChain [4] delta = 0.8 (Default)\nChain [4] kappa = 0.75 (Default)\nChain [4] t0 = 10 (Default)\nChain [4] init_buffer = 75 (Default)\nChain [4] term_buffer = 50 (Default)\nChain [4] window = 25 (Default)\nChain [4] save_metric = false (Default)\nChain [4] algorithm = hmc (Default)\nChain [4] hmc\nChain [4] engine = nuts (Default)\nChain [4] nuts\nChain [4] max_depth = 10 (Default)\nChain [4] metric = diag_e (Default)\nChain [4] metric_file =  (Default)\nChain [4] stepsize = 1 (Default)\nChain [4] stepsize_jitter = 0 (Default)\nChain [4] num_chains = 1 (Default)\nChain [4] id = 4\nChain [4] data\nChain [4] file = /tmp/tmpbd3i87cn/m4hm5zyi.json\nChain [4] init = 2 (Default)\nChain [4] random\nChain [4] seed = 26068\nChain [4] output\nChain [4] file = /tmp/tmpbd3i87cn/binomial_toymodel_013uxepct5/binomial_toymodel_01-20241101120108_4.csv\nChain [4] diagnostic_file =  (Default)\nChain [4] refresh = 100 (Default)\nChain [4] sig_figs = -1 (Default)\nChain [4] profile_file = profile.csv (Default)\nChain [4] save_cmdstan_config = false (Default)\nChain [4] num_threads = 1 (Default)\nChain [4] \nChain [1] Iteration:    1 / 2000 [  0%]  (Warmup)\nChain [2] output\nChain [2] file = /tmp/tmpbd3i87cn/binomial_toymodel_013uxepct5/binomial_toymodel_01-20241101120108_2.csv\nChain [2] diagnostic_file =  (Default)\nChain [2] refresh = 100 (Default)\nChain [2] sig_figs = -1 (Default)\nChain [2] profile_file = profile.csv (Default)\nChain [2] save_cmdstan_config = false (Default)\nChain [2] num_threads = 1 (Default)\nChain [2] \nChain [2] \nChain [2] Gradient evaluation took 4e-06 seconds\nChain [2] 1000 transitions using 10 leapfrog steps per transition would take 0.04 seconds.\nChain [2] Adjust your expectations accordingly!\nChain [2] \nChain [2] \nChain [2] Iteration:    1 / 2000 [  0%]  (Warmup)\nChain [3] method = sample (Default)\nChain [1] Iteration:  100 / 2000 [  5%]  (Warmup)\nChain [3] sample\nChain [3] num_samples = 1000 (Default)\nChain [3] num_warmup = 1000 (Default)\nChain [3] save_warmup = false (Default)\nChain [3] thin = 1 (Default)\nChain [3] adapt\nChain [3] engaged = true (Default)\nChain [3] gamma = 0.05 (Default)\nChain [3] delta = 0.8 (Default)\nChain [3] kappa = 0.75 (Default)\nChain [3] t0 = 10 (Default)\nChain [3] init_buffer = 75 (Default)\nChain [3] term_buffer = 50 (Default)\nChain [3] window = 25 (Default)\nChain [3] save_metric = false (Default)\nChain [3] algorithm = hmc (Default)\nChain [3] hmc\nChain [3] engine = nuts (Default)\nChain [3] nuts\nChain [2] Iteration:  100 / 2000 [  5%]  (Warmup)\nChain [3] max_depth = 10 (Default)\nChain [4] \nChain [3] metric = diag_e (Default)\nChain [3] metric_file =  (Default)\nChain [3] stepsize = 1 (Default)\nChain [3] stepsize_jitter = 0 (Default)\nChain [3] num_chains = 1 (Default)\nChain [3] id = 3\nChain [3] data\nChain [3] file = /tmp/tmpbd3i87cn/m4hm5zyi.json\nChain [3] init = 2 (Default)\nChain [3] random\nChain [3] seed = 26068\nChain [3] output\nChain [3] file = /tmp/tmpbd3i87cn/binomial_toymodel_013uxepct5/binomial_toymodel_01-20241101120108_3.csv\nChain [3] diagnostic_file =  (Default)\nChain [3] refresh = 100 (Default)\nChain [3] sig_figs = -1 (Default)\nChain [3] profile_file = profile.csv (Default)\nChain [3] save_cmdstan_config = false (Default)\nChain [3] num_threads = 1 (Default)\nChain [3] \nChain [4] Gradient evaluation took 2e-06 seconds\nChain [4] 1000 transitions using 10 leapfrog steps per transition would take 0.02 seconds.\nChain [4] Adjust your expectations accordingly!\nChain [4] \nChain [4] \nChain [4] Iteration:    1 / 2000 [  0%]  (Warmup)\nChain [1] Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain [3] \nChain [3] Gradient evaluation took 2e-06 seconds\nChain [3] 1000 transitions using 10 leapfrog steps per transition would take 0.02 seconds.\nChain [3] Adjust your expectations accordingly!\nChain [2] Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain [3] \nChain [3] \nChain [4] Iteration:  100 / 2000 [  5%]  (Warmup)\nChain [3] Iteration:    1 / 2000 [  0%]  (Warmup)\nChain [1] Iteration:  300 / 2000 [ 15%]  (Warmup)\nChain [2] Iteration:  300 / 2000 [ 15%]  (Warmup)\nChain [4] Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain [3] Iteration:  100 / 2000 [  5%]  (Warmup)\nChain [1] Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain [2] Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain [4] Iteration:  300 / 2000 [ 15%]  (Warmup)\nChain [3] Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain [1] Iteration:  500 / 2000 [ 25%]  (Warmup)\nChain [2] Iteration:  500 / 2000 [ 25%]  (Warmup)\nChain [4] Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain [3] Iteration:  300 / 2000 [ 15%]  (Warmup)\nChain [1] Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain [2] Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain [4] Iteration:  500 / 2000 [ 25%]  (Warmup)\nChain [1] Iteration:  700 / 2000 [ 35%]  (Warmup)\nChain [3] Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain [2] Iteration:  700 / 2000 [ 35%]  (Warmup)\nChain [4] Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain [1] Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain [3] Iteration:  500 / 2000 [ 25%]  (Warmup)\nChain [2] Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain [1] Iteration:  900 / 2000 [ 45%]  (Warmup)\nChain [4] Iteration:  700 / 2000 [ 35%]  (Warmup)\nChain [3] Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain [2] Iteration:  900 / 2000 [ 45%]  (Warmup)\nChain [4] Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain [1] Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain [1] Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain [3] Iteration:  700 / 2000 [ 35%]  (Warmup)\nChain [2] Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain [4] Iteration:  900 / 2000 [ 45%]  (Warmup)\nChain [2] Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain [3] Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain [4] Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain [4] Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain [1] Iteration: 1100 / 2000 [ 55%]  (Sampling)\nChain [3] Iteration:  900 / 2000 [ 45%]  (Warmup)\nChain [2] Iteration: 1100 / 2000 [ 55%]  (Sampling)\nChain [3] Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain [3] Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain [4] Iteration: 1100 / 2000 [ 55%]  (Sampling)\nChain [1] Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain [2] Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain [3] Iteration: 1100 / 2000 [ 55%]  (Sampling)\nChain [1] Iteration: 1300 / 2000 [ 65%]  (Sampling)\nChain [4] Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain [2] Iteration: 1300 / 2000 [ 65%]  (Sampling)\nChain [3] Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain [4] Iteration: 1300 / 2000 [ 65%]  (Sampling)\nChain [1] Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain [2] Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain [3] Iteration: 1300 / 2000 [ 65%]  (Sampling)\nChain [1] Iteration: 1500 / 2000 [ 75%]  (Sampling)\nChain [4] Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain [2] Iteration: 1500 / 2000 [ 75%]  (Sampling)\nChain [1] Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain [3] Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain [4] Iteration: 1500 / 2000 [ 75%]  (Sampling)\nChain [2] Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain [1] Iteration: 1700 / 2000 [ 85%]  (Sampling)\nChain [4] Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain [3] Iteration: 1500 / 2000 [ 75%]  (Sampling)\nChain [2] Iteration: 1700 / 2000 [ 85%]  (Sampling)\nChain [1] Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain [4] Iteration: 1700 / 2000 [ 85%]  (Sampling)\nChain [3] Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain [2] Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain [1] Iteration: 1900 / 2000 [ 95%]  (Sampling)\nChain [4] Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain [3] Iteration: 1700 / 2000 [ 85%]  (Sampling)\nChain [2] Iteration: 1900 / 2000 [ 95%]  (Sampling)\nChain [1] Iteration: 2000 / 2000 [100%]  (Sampling)\nChain [1] \nChain [1] Elapsed Time: 0.008 seconds (Warm-up)\nChain [1] 0.016 seconds (Sampling)\nChain [1] 0.024 seconds (Total)\nChain [1] \nChain [4] Iteration: 1900 / 2000 [ 95%]  (Sampling)\nChain [3] Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [1] \nChain [2] Iteration: 2000 / 2000 [100%]  (Sampling)\nChain [2] \nChain [2] Elapsed Time: 0.009 seconds (Warm-up)\nChain [2] 0.017 seconds (Sampling)\nChain [2] 0.026 seconds (Total)\nChain [2] \nChain [1] \nChain [2] \nChain [4] Iteration: 2000 / 2000 [100%]  (Sampling)\nChain [3] Iteration: 1900 / 2000 [ 95%]  (Sampling)\nChain [4] \nChain [4]  Elapsed Time: 0.008 seconds (Warm-up)\nChain [4]                0.017 seconds (Sampling)\nChain [4]                0.025 seconds (Total)\nChain [4] \nChain [4] \nChain [3] Iteration: 2000 / 2000 [100%]  (Sampling)\nChain [3] \nChain [3] Elapsed Time: 0.008 seconds (Warm-up)\nChain [3] 0.019 seconds (Sampling)\nChain [3] 0.027 seconds (Total)\nChain [3] \nChain [3] \n\n\n\n\nCode\nfit.summary()\n\n\n\n\n\n\n\n\n\nMean\nMCSE\nStdDev\n5%\n50%\n95%\nN_Eff\nN_Eff/s\nR_hat\n\n\n\n\nlp__\n-14.263100\n0.017512\n0.718309\n-15.743200\n-13.993000\n-13.762900\n1682.43\n24383.0\n1.00052\n\n\ntheta\n0.316506\n0.002404\n0.095760\n0.165167\n0.310247\n0.481013\n1586.53\n22993.3\n1.00275",
    "crumbs": [
      "Bayesian methods",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>二項分布を用いたベイジアンモデリング</span>"
    ]
  },
  {
    "objectID": "posts/bayesianstatistics101/chapter_header.html",
    "href": "posts/bayesianstatistics101/chapter_header.html",
    "title": "Bayesian methods",
    "section": "",
    "text": "ベイズ法の考え方\nある集団の特性がパラメーター \\(\\theta\\) として表現されるとします．集団の一部についてデータ \\(y\\) が観測されたとき， その \\(y\\) からの情報はパラメーター \\(\\theta\\) についての不確実性(uncertainty)を減らすことになります． ベイズ推測(Bayesian inference)とはこの不確実性の変化を測ることが直接的な目的となります．\n▶  事前分布と事後分布\n標本空間 \\(\\mathcal{Y}\\), パラメーター空間 \\(\\Theta\\) としたとき，ベイズ学習は \\(y, \\theta\\) に関する信念を \\(\\mathcal{Y}\\) と \\(\\Theta\\) の確率分布によって表現するところから始まります．\nまず，\\(\\theta\\in\\Theta\\) について事前分布 \\(p(\\theta)\\) を設定します． \\(p(\\theta)\\) は，\\(\\theta\\) が母集団の真の特性を表すとどれだけ分析者が信じているか？を表していると解釈できます．\nデータ \\(y\\) が観測された後，ベイズルールに従って \\(\\theta\\) に関する信念を更新します．このとき現れるのが事後分布 \\(p(\\theta\\vert y)\\) ですが，これはデータ \\(y\\) が観測された後に \\(\\theta\\) が真の値であるとどれだけ信じているかを表すことに対応しています．\n▶  ベイズルール\n\\[\np(\\theta\\vert y) = \\frac{p(y\\vert \\theta)p(\\theta)}{\\int_{\\Theta}p(y\\vert \\tilde\\theta)p(\\tilde\\theta)\\,\\mathrm{d}\\tilde\\theta}\n\\]\nベイズルールが示している内容は．事後分布がどうあるべきかではなく，新たな情報を得たときに事後分布はどう変化すべきか？です．",
    "crumbs": [
      "Bayesian methods"
    ]
  },
  {
    "objectID": "posts/bayesianstatistics101/chapter_header.html#ベイズ法の考え方",
    "href": "posts/bayesianstatistics101/chapter_header.html#ベイズ法の考え方",
    "title": "Bayesian methods",
    "section": "",
    "text": "Def: 確率(probability) \nベイズ法における確率(probability) は，未知の量について人々の持つ情報や信念(belief)を表すものと解釈される．",
    "crumbs": [
      "Bayesian methods"
    ]
  }
]